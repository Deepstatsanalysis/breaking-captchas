{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"Breaking captchas - Computer Vision.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"GKTuV427QW_r","colab_type":"text"},"source":["# Quebrando captchas vulneráveis - Visão computacional\n","\n","---\n","\n","Nesse notebook veremos os princípios utilizados e os passos necessários para *quebrar CAPTCHAs*, desde o processamento de imagens até extração de informações . Para isso, utilizaremos as bilbiotecas: Selenium para extrair dados de páginas web, OpenCV para o processamento de imagens e scikit-learn para converter os dados da imagens em informações importantes, que nesse caso é o conteúdo dos *CAPTCHAs*."]},{"cell_type":"markdown","metadata":{"id":"wlUpUewxY_LY","colab_type":"text"},"source":["<center><img width=400 alt=\"computer_vision\" src=\"https://miro.medium.com/max/1200/1*s9raSe9mLeSSuxE3API-ZA.gif\"> <img width=300 alt=\"computer_vision\" src=\"https://tulip.co/wp-content/uploads/barcode_ocr.gif\"> <br>Fonte: https://towardsdatascience.com/how-to-do-everything-in-computer-vision-2b442c469928 e https://tulip.co/blog/tulip/give-your-apps-the-power-of-vision/\n","</center>"]},{"cell_type":"markdown","metadata":{"id":"aYpYTUH0StYX","colab_type":"text"},"source":["## Dependências\n","\n","Nesse momento iremos instalar e importar as dependências necessárias para executar nosso notebook."]},{"cell_type":"code","metadata":{"id":"Xd_FdrjyMh7D","colab_type":"code","colab":{}},"source":["# Vamos instalar algumas bibliotecas e configurar algumas informações para o google colab. \n","\n","!pip install selenium\n","!apt-get update\n","!apt install chromium-chromedriver\n","!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n","import sys\n","sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n","\n","# Importando as bibliotecas necessárias para o projeto\n","from selenium import webdriver # Para realizar o webscraping\n","from io import BytesIO # Para conversão das imagens na página para OpenCV\n","import matplotlib.pyplot as plt # Para mostrar os resultados dos processamentos\n","import cv2, numpy as np # Para manipular e realizar o processamento de imagens\n","import random # Para gerar número aleatórios\n","from joblib import load # Para importar o modelo de rede neural\n","\n","SZ_W = 15\n","SZ_H = 20\n","\n","chrome_options = webdriver.ChromeOptions()\n","chrome_options.add_argument('--headless')\n","chrome_options.add_argument('--no-sandbox')\n","chrome_options.add_argument('--disable-dev-shm-usage')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kRp6x86lNWgT","colab_type":"code","colab":{}},"source":["# Montando o drive para poder acessar nossos arquivos.\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Definindo o caminho dos arquivos para o nosso projeto.\n","root_path = \"drive/My Drive/campus-party-captchas\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cLB3mCV5W8_u","colab_type":"text"},"source":["---\n","\n","<left><img width=\"100\" alt=\"creating a repo\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","## Codificação"]},{"cell_type":"markdown","metadata":{"id":"CsWroapWYxrM","colab_type":"text"},"source":["<center> <h1>Selenium + Chrome webdriver</h1><img alt=\"webdriver-architecture\" src=\"https://d1jnx9ba8s6j9r.cloudfront.net/blog/wp-content/uploads/2017/04/webdriver-working.png\"> Fonte: https://www.edureka.co/blog/selenium-tutorial/\n","</center>\n","\n","\n","Selenium é uma biblioteca que nos permite navegar por páginas web e realizar ações **humanas** predefinidas, como preencher campos, ações de cliques e busca de termos na página. O que facilita as ações de *web crawling*, cujo propósito é criar scripts ou programas que automatizem tarefas."]},{"cell_type":"markdown","metadata":{"id":"_II1q9e2fFZR","colab_type":"text"},"source":["### Inicializando o webdriver"]},{"cell_type":"code","metadata":{"id":"eyXHE0tYMWiG","colab_type":"code","colab":{}},"source":["# Instanciando nosso driver\n","driver = webdriver.Chrome('chromedriver',options=chrome_options)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xTXnArPjMWiW","colab_type":"text"},"source":["### Realizando acesso a página\n","\n","Nesse momento é realizado o acesso a página para obter a imagem do captcha."]},{"cell_type":"code","metadata":{"id":"CDqj9t05MWia","colab_type":"code","colab":{}},"source":["# Definindo o caminho\n","url = 'http://captchas-generator.herokuapp.com/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gVfnYALnMWig","colab_type":"code","colab":{}},"source":["# Carregando a página solicitada\n","driver.get(url)\n","\n","# Obtendo print da página\n","fullPage = driver.get_screenshot_as_png()\n","\n","# Convertendo para Mat(OpenCV)\n","img_stream = BytesIO(fullPage)\n","img = cv2.imdecode(np.frombuffer(img_stream.read(), np.uint8), 1)\n","img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jY0KudPPfPKH","colab_type":"code","colab":{}},"source":["# Mostrando a imagem carregada\n","plt.figure(figsize=(15,10))\n","plt.imshow(img)\n","plt.show"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sPABMHA0fPi3","colab_type":"code","colab":{}},"source":["captcha = driver.find_element_by_id(\"captcha_image\") # Encontrando o captcha na página pelo id\n","loc = captcha.location # Obtendo localização em pixels\n","size = captcha.size # Obtendo o tamanho da imagem\n","img = img[ int(loc['y']): int(loc['y'] + size['height']) , int(loc['x']): int(loc['x'] + size['width']) ] # Delimitando a imagem ao captcha\n","gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # Convertendo para escala de cinza"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wDsE9TcnMWio","colab_type":"code","colab":{}},"source":["# Mostrando o captcha obtido\n","plt.imshow(gray, cmap='gray')\n","plt.show"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_vjk6Qt1MWix","colab_type":"text"},"source":["### Estágio de processamento de imagens\n","\n","A partir desse ponto é iniciado a etapa de processamento."]},{"cell_type":"markdown","metadata":{"id":"XM-3YYWNhhdB","colab_type":"text"},"source":["#### Binarização"]},{"cell_type":"markdown","metadata":{"id":"AtEsB0yVfT1c","colab_type":"text"},"source":["<center> <h1>Limiarização Adaptativa </h1><img alt=\"opencv_thresholding\" src=\"https://docs.opencv.org/3.4.3/ada_threshold.jpg\"><br> Fonte: https://docs.opencv.org/3.4.3/d7/d4d/tutorial_py_thresholding.html\n","</center>\n","\n","O processo de limiarização consiste na transformação de uma imagem em escala de cinza para uma imagem binária. A limiarização mais simples é a definida por um **limite** predefinido, onde tudo que for menor que esse limite é transformado para um valor, e maior que ele para outro valor, ilustrado no topo esquerdo da Figura acima. \n","\n","Outros métodos mais complexos e mais eficientes também podem ser aplicados, como: <a href=\"https://en.wikipedia.org/wiki/Otsu%27s_method\"> Otsu's method</a> e <a href=\"https://www.researchgate.net/publication/269984781_Adaptive_thresholding_A_comparative_study\">limiarização adaptativa</a>. Este utiliza-se da vizinhaça para descobrir o limite, ao invés de um valor predefinido."]},{"cell_type":"code","metadata":{"id":"EP2nK371MWi0","colab_type":"code","colab":{}},"source":["# Conversão da imagem em escala de cinza para preto e branco.\n","binary = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,75,10)\n","plt.imshow(binary, cmap='gray')\n","plt.show"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0hV_-GWihoBo","colab_type":"text"},"source":["#### Filtro de mediana\n","\n","<center> <h1>Aplicação do filtro</h1><img alt=\"opencv_median\" src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--Wt8y6hP6--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://cdn-images-1.medium.com/max/800/1%2AVyzJxDrLrC-OqkV5LHhjQQ.gif\"><br> Fonte: https://dev.to/enzoftware/how-to-build-amazing-image-filters-with-python-median-filter---sobel-filter---5h7\n","</center>\n","\n","O filtro de mediana é uns dos pré-processamentos mais utilizados na literatura quando o assunto é rúidos, principalmente os de sal e pipenta. \n","\n","<center><img width=300 alt=\"lena_normal\" src=\"https://www.cosy.sbg.ac.at/~pmeerw/Watermarking/lena_gray.gif\"> <img width=300 alt=\"lena_noise\" src=\"https://raw.githubusercontent.com/timlentse/Add-Salt_Pepper_noise/master/add%20noise%20%20image.png\">\n","</center>\n","\n","Através de uma janela deslizante, o algoritmo busca o valor central (mediano) entre todos os valores dessa janela e o utiliza como valor do pixel para nova imagem. "]},{"cell_type":"code","metadata":{"id":"5ED2W-mSMWi7","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(20,5))\n","filtered = cv2.medianBlur(binary, 3) # Primeira aplicação\n","ax1 = plt.subplot(221)\n","ax1.imshow(filtered, cmap='gray')\n","\n","filtered = cv2.medianBlur(filtered, 3) # Segunda aplicação\n","ax2 = plt.subplot(222)\n","ax2.imshow(filtered, cmap='gray')\n","\n","filtered = cv2.medianBlur(filtered, 3) # Terceira aplicação\n","ax3 = plt.subplot(223)\n","ax3.imshow(filtered, cmap='gray')\n","\n","filtered = cv2.medianBlur(filtered, 3) # Quarta aplicação\n","ax4 = plt.subplot(224)\n","ax4.imshow(filtered, cmap='gray')\n","\n","ax1.axis('off')\n","ax2.axis('off')\n","ax3.axis('off')\n","ax4.axis('off')\n","\n","ax1.text(0.5,-0.1, \"Median blur 1\", ha=\"center\", transform=ax1.transAxes)\n","ax2.text(0.5,-0.1, \"Median blur 2\", ha=\"center\", transform=ax2.transAxes)\n","ax3.text(0.5,-0.1, \"Median blur 3\", ha=\"center\", transform=ax3.transAxes)\n","ax4.text(0.5,-0.1, \"Final result\", ha=\"center\", transform=ax4.transAxes)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nsVsUCjwMWjE","colab_type":"text"},"source":["#### Buscando contornos"]},{"cell_type":"markdown","metadata":{"id":"NqfSMdm1BA7J","colab_type":"text"},"source":["<center><h1>Encontrando contornos com OpenCV</h1><img alt=\"opencv_contour\" src=\"https://www.pyimagesearch.com/wp-content/uploads/2016/01/center_of_contour_results.gif\"><br> Fonte: https://www.pyimagesearch.com/2016/02/01/opencv-center-of-contour/\n","</center>\n","\n","O processo de buscar contornos,consiste em analisar os pixels nas imagens e realizar o agrupamento desses pixels por meio da proximidade (distância e intensidade). Bastante utilizados na análise de silhuetas e na busca por objetos."]},{"cell_type":"code","metadata":{"id":"a7Dakk_pMWjI","colab_type":"code","colab":{}},"source":["_, contours, _ = cv2.findContours(filtered, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # Obtendo os contornos\n","\n","img_cp = img.copy()\n","\n","# Mostrando os contornos obtidos pelo algoritmo\n","for c in range(len(contours)):\n","    x,y,w,h = cv2.boundingRect(contours[c])\n","    cv2.rectangle(img_cp,(x,y),(x+w,y+h),\n","                 (random.randint(0, 255), \n","                  random.randint(0, 255), \n","                  random.randint(0, 255)),1)\n","\n","plt.figure(figsize=(15,10))\n","plt.imshow(img_cp)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6V40u69wMWjP","colab_type":"text"},"source":["#### Ordenando pelo tamanho do contorno (número de pixels) e pela posição"]},{"cell_type":"code","metadata":{"id":"t78LMcwVMWjR","colab_type":"code","colab":{}},"source":["# Definição da função que retorna o primeiro ponto a esquerda do contorno\n","def top_left(c):\n","    x,y,_,_ = cv2.boundingRect(c)\n","    return (x,y)\n","\n","contours.sort(key=len,reverse=True) # Realizando a ordenação pelo tamanho (de maneira decrescente)\n","contours = contours[:min(6, len(contours))] # Obtendo os seis primeiros contornos\n","contours.sort(key=top_left) # Sorteando os 6 (ou menos) contornos pela posição\n","\n","img_cp = img.copy()\n","\n","# Mostrando os resultados finais\n","for c in range(len(contours)):\n","    x,y,w,h = cv2.boundingRect(contours[c])\n","    cv2.rectangle(img_cp,(x,y),(x+w,y+h),(random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)),1)\n","\n","plt.figure(figsize=(15,10))\n","plt.imshow(img_cp)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E0ePssgLMWjb","colab_type":"code","colab":{}},"source":["fig_chars = plt.figure()\n","\n","# Separando e mostrando os candidatos a digitos\n","for c in range(len(contours)):\n","    x,y,w,h = cv2.boundingRect(contours[c])\n","    crop = np.zeros(filtered.shape, dtype=np.uint8)\n","    cv2.drawContours(crop, contours, c, 255, -1)\n","    crop = cv2.bitwise_and(crop, filtered)\n","    crop = crop[y:y+h, x:x+w]\n","\n","    crop = cv2.resize(crop, (SZ_W, SZ_H), interpolation = cv2.INTER_CUBIC)\n","    fig_chars.add_subplot(1, 6, c+1)\n","    plt.imshow(crop, cmap = 'gray')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fMnO6QXbMWjh","colab_type":"text"},"source":["#### Corrigindo a orientação dos dígitos"]},{"cell_type":"markdown","metadata":{"id":"4SSRXMn4GxLn","colab_type":"text"},"source":["<center><h1>Detectando inclinações</h1><img alt=\"opencv_skew\" src=\"https://www.pyimagesearch.com/wp-content/uploads/2017/02/text_skew_pos41_results.png\"><br> Fonte: https://www.pyimagesearch.com/2017/02/20/text-skew-correction-opencv-python/\n","</center>\n","\n","A correção da inclinação textual é corrigida através de 2 momentos centrais, o qual é verificado a razão entre os dois eixos do plano."]},{"cell_type":"code","metadata":{"id":"wtQWS8w1MWjk","colab_type":"code","colab":{}},"source":["# Definindo a função que corrige a orientação dos dígitos\n","def deskew(img):\n","    m = cv2.moments(img)\n","    \n","    if abs(m['mu02']) < 1e-2:\n","        return img.copy()    \n","    skew = m['mu11']/m['mu02']    \n","    M = np.float32([[1, skew, -0.5*SZ_W*skew], [0, 1, 0]])    \n","    img = cv2.warpAffine(img, M, (SZ_W, SZ_H), flags=cv2.WARP_INVERSE_MAP | cv2.INTER_CUBIC)\n","    return img"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6QWvZ75bMWjr","colab_type":"code","colab":{}},"source":["fig_chars = plt.figure()\n","number_images = []\n","\n","# Itera sobre os contornos e aplica a correção\n","for c in range(len(contours)):\n","    x,y,w,h = cv2.boundingRect(contours[c])\n","    crop = np.zeros(filtered.shape, dtype=np.uint8)\n","    cv2.drawContours(crop, contours, c, 255, -1)\n","    crop = cv2.bitwise_and(crop, filtered)\n","    crop = crop[y:y+h, x:x+w]\n","\n","    crop = cv2.resize(crop, (SZ_W, SZ_H), interpolation = cv2.INTER_CUBIC) # Redimensionando o contorno para (15x20)\n","    skewed = deskew(crop) # Aplicação da correção\n","    fig_chars.add_subplot(1, 6, c+1)\n","    plt.imshow(skewed, cmap = 'gray')\n","    number_images.append( skewed.flatten().tolist() ) # Adiciona a lista de números os dígitos selecionados."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SaTAzHYlMWjw","colab_type":"text"},"source":["###  Classificação dos dígitos\n","\n","Nessa etapa será realizado a classificação dos dígitos através de um modelo construido com aprendizado de máquina."]},{"cell_type":"markdown","metadata":{"id":"ARz404IhvSx0","colab_type":"text"},"source":["#### Rede neural"]},{"cell_type":"markdown","metadata":{"id":"jwvE2TV8ISHL","colab_type":"text"},"source":["<center><h1>Arquitetura de uma RN</h1><img alt=\"opencv_skew\" src=\"https://miro.medium.com/max/700/1*ui3IvoiVYBFtaU0auj63ew.gif\"><br> Fonte: https://medium.com/@pallawi.ds/ai-starter-train-and-test-your-first-neural-network-classifier-in-keras-from-scratch-b6a5f3b3ebc4\n","</center>\n","\n","Redes neurais são modelos computacionais compostos de\n","camadas de elementos de computação interconectados, os neurônios.\n","Elas são capazes de assimilar padrões em dados e, com isso,\n","realizar predições, diagnósticos, reconhecimentos, entre outros.\n"]},{"cell_type":"code","metadata":{"id":"OBj0zoRzMWjy","colab_type":"code","colab":{}},"source":["# Carregando o modelo de rede neural\n","mlp = load(root_path + '/models/mlp.save')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7U_LjOotMWj6","colab_type":"code","colab":{}},"source":["# Realizando a predição\n","mlp_result = mlp.predict(number_images)\n","mlp_result = ''.join( [str(x) for x in mlp_result] )\n","print(mlp_result)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1IMZqI7rMWj_","colab_type":"text"},"source":["## Finalizando o acesso à página\n"]},{"cell_type":"markdown","metadata":{"id":"fqpgdBAKwFxt","colab_type":"text"},"source":["### Preenchendo os campos de texto"]},{"cell_type":"code","metadata":{"id":"sbE89DKbMWkA","colab_type":"code","colab":{}},"source":["captcha_key = driver.find_element_by_id('captcha_input')\n","button = driver.find_element_by_id('captcha_btn')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lz2XtUD_wQ0z","colab_type":"text"},"source":["### Submetendo os dados"]},{"cell_type":"code","metadata":{"id":"4YgmniFjMWkH","colab_type":"code","colab":{}},"source":["captcha_key.send_keys(mlp_result)\n","button.click()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Gtm1oedTb5c","colab_type":"text"},"source":["## Validando resultados"]},{"cell_type":"code","metadata":{"id":"D5yT5G6mMWkN","colab_type":"code","colab":{}},"source":["# Obtendo página de resultado\n","page = driver.page_source"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1twiZjBFSvBq","colab_type":"code","colab":{}},"source":["try:\n","    success_message = driver.find_element_by_id('success') # Verifica a existência do id com a mensagem de sucesso\n","    print(\"Página carregada com sucesso!\")\n","except:\n","    print(\"CAPTCHA inválida, tente novamente!\") # Caso der errado\n","\n","# Mostrando a página obtida\n","resultPage = driver.get_screenshot_as_png()\n","result_stream = BytesIO(resultPage)\n","result_img = cv2.imdecode(np.frombuffer(result_stream.read(), np.uint8), 1)\n","result_img = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)\n","\n","plt.figure(figsize=(15,10))\n","plt.imshow(result_img)\n","plt.show"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Hc9Zzgx6BoQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}